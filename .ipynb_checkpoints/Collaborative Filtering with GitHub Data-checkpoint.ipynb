{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering #\n",
    "\n",
    "Collaborative filtering is a popular approach to creating recommender systems. Suppose we have the following problem:\n",
    "\n",
    "User A gave five stars to _Titanic_ and _The Notebook_, and one star to _Captain America_ and _Dark Knight Rises_. Should we recommend to User A a film like _Love Actually_? What about _Batman vs Superman_?\n",
    "\n",
    "In this case it's easy to tell what User A prefers since we have prior knowledge about the films. But how can we develop recommendations without this knowledge? \n",
    "\n",
    "It turns out that if we have rating data from many users it's possible to learn the underlying features that define a movie (genre, certain actors/directors, etc.) as well as the preferences of each user for each feature. Then, by identifying the features for a particular movie, and the preferences of a particular user, we can decide whether that movie would be a good recommendation. \n",
    "\n",
    "# Low Rank Matrix Factorization #\n",
    "\n",
    "One method of implementing collaborative filtering is low rank matrix factorization. Suppose we have a matrix of ratings, with one column for each user and one row for each item. Call this matrix $Y$. A small number of the elements in the matrix will have values (the rating user A gives to item B, if it exists), but the vast majority of elements will be unknown. We also have a matrix $R$ which contains 1 in locations where a rating exists and 0 where a rating has not been given. Both $R$ and $Y$ have dimension $n_{items}$ by $n_{users}$. \n",
    "\n",
    "The process described above of learning underlying features and preferences is described mathematically by:\n",
    "\n",
    "$ Y = X \\theta^{T} $\n",
    "\n",
    "$X$ is a matrix with dimension $n_{items}$ by $n_{features}$ and $\\theta$ is a matrix with dimension $n_{users}$ by $n_{features}$. Each row in $X$ is the representation of a particular item as a linear combination of features, and each row in $\\theta$ represents the preferences of a particular user for each feature. Note that a feature might be some characteristic such as genre or author - but it may also be very difficult to interpret. The beauty of the algorithm is that it will automatically choose the most meaningful features.\n",
    "\n",
    "# Training and Implementation #\n",
    "\n",
    "The goal of our algorithm is to find appropriate matrices $X$ and $\\theta$ such that $X \\theta^{T}$ approximates $Y$. However, it only needs to approximate $Y$'s values where a rating has actually been given - for some user A who has not rated item B, the value given by $X \\theta^{T}$ at column A and row B is the _predicted_ rating that user A will give to item B. \n",
    "\n",
    "We can find $X$ and $\\theta$ using gradient descent. The loss function will be the sum-of-squares loss between $X \\theta^{T}$ and $Y$, _but only evaluated on locations where a rating has been given_, i.e. where $R_{i,j}=1$. Similarly, the gradient is only computed at these locations as well. \n",
    "\n",
    "For this particular analysis, the goal is to recommend programming languages for you to learn, given some languages you already like. We will approximate the preferences of users with the languages used in GitHub repositories. The items we rate will be languages. Once we compute $X$ and $\\theta$, the recommended languages will be those with the highest predicted ratings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquiring Data From BigQuery #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import a relatively small number of repositories (for speed) and their language details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 1\n",
      "C: 16039 bytes\n",
      "C++: 24550 bytes\n",
      "Makefile: 290 bytes\n",
      "\n",
      "Repository 2\n",
      "CSS: 16755 bytes\n",
      "JavaScript: 141 bytes\n",
      "\n",
      "Repository 3\n",
      "CSS: 683 bytes\n",
      "HTML: 4883 bytes\n",
      "JavaScript: 599 bytes\n",
      "Ruby: 15180 bytes\n",
      "\n",
      "Repository 4\n",
      "C: 905071 bytes\n",
      "C++: 75392 bytes\n",
      "CMake: 4605 bytes\n",
      "\n",
      "Repository 5\n",
      "CSS: 5926 bytes\n",
      "PHP: 30737 bytes\n",
      "\n",
      "Repository 6\n",
      "CSS: 21944 bytes\n",
      "HTML: 20866 bytes\n",
      "JavaScript: 408 bytes\n",
      "Ruby: 4206 bytes\n",
      "\n",
      "Repository 7\n",
      "CSS: 4355 bytes\n",
      "Go: 2121278 bytes\n",
      "HTML: 84972 bytes\n",
      "JavaScript: 82734 bytes\n",
      "NSIS: 2834 bytes\n",
      "Shell: 4616 bytes\n",
      "\n",
      "Repository 8\n",
      "CSS: 1174 bytes\n",
      "HTML: 2578 bytes\n",
      "JavaScript: 12746 bytes\n",
      "\n",
      "Repository 9\n",
      "Groovy: 685 bytes\n",
      "Java: 110490 bytes\n",
      "\n",
      "Repository 10\n",
      "CSS: 8352 bytes\n",
      "HTML: 33485 bytes\n",
      "JavaScript: 1742 bytes\n",
      "\n",
      "...\n",
      "145 repositories\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "#random sample of 300 repositories\n",
    "QUERY = \"\"\"\n",
    "        SELECT repo_name, language\n",
    "        FROM `bigquery-public-data.github_repos.languages`\n",
    "        ORDER BY rand()\n",
    "        LIMIT 300\n",
    "        \"\"\"\n",
    "\n",
    "query_job = client.query(QUERY)\n",
    "\n",
    "#filter out repositories with only one language\n",
    "iterator = query_job.result(timeout=30)\n",
    "rows = list(iterator)\n",
    "rows = list(filter(lambda row: len(row.language)>1,rows))\n",
    "\n",
    "#print some repositories\n",
    "for i in range(10):\n",
    "    print('Repository '+str(i+1))\n",
    "    for j in rows[i].language:\n",
    "        print(j[u'name']+': '+str(j[u'bytes'])+' bytes')\n",
    "    print('')\n",
    "print('...')\n",
    "print(str(len(rows))+' repositories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Languages #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of all languages in the given sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLSL\n",
      "TypeScript\n",
      "Java\n",
      "ApacheConf\n",
      "JavaScript\n",
      "Makefile\n",
      "QMake\n",
      "Perl\n",
      "M4\n",
      "Groff\n",
      "...\n",
      "42 languages\n"
     ]
    }
   ],
   "source": [
    "#create dictionary of language names to matrix columns\n",
    "names = {}\n",
    "for i in range(len(rows)):\n",
    "    for j in rows[i].language:\n",
    "        if j[u'name'] in names:\n",
    "            names[j[u'name']]+=1\n",
    "        else:\n",
    "            names[j[u'name']]=1\n",
    "\n",
    "#filter out languages that only occur once\n",
    "names = [n for n in names if names[n]>1]\n",
    "for i in range(10):\n",
    "    print(names[i])\n",
    "print('...')\n",
    "\n",
    "#print some languages\n",
    "name_to_index = {}\n",
    "for j,i in enumerate(names):\n",
    "    name_to_index[i] = j\n",
    "print(str(len(names))+\" languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repository-Language Matrix #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix where each row represents a repository and each column represents a language. This matrix is our Y (i.e. what we are trying to predict). Here, if a language A is used in repository B, this is considered as repository B giving A a rating. If A is not used in B, then there is no rating (rather than a rating of 0). \n",
    "\n",
    "The value in the matrix is the number of bytes in the repository in that particular language, divided by the sum of the number of bytes of each language in the repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "#create matrix\n",
    "global mat\n",
    "mat = np.zeros((len(rows),len(names)))\n",
    "for i,row in enumerate(rows):\n",
    "    total = sum([lang[u'bytes'] for lang in row[1]])+0.0\n",
    "    for lang in row.language:\n",
    "        if lang[u'name'] in name_to_index:\n",
    "            mat[i][name_to_index[lang[u'name']]] = lang[u'bytes']/total\n",
    "mat = mat[~np.all(mat==0,axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PCA we can define roughly the number of features we want to identify the low rank matrix factorization. The graph below shows the amount of unexplained variance plotted against the number of components used. The \"elbow\" of the graph (at around n=12) is typically used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fba373785d0>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fba490b8390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#compute PCA\n",
    "n_components = min(50,len(names))\n",
    "pca = PCA(n_components=n_components)\n",
    "transformed = pca.fit_transform(mat) \n",
    "\n",
    "#display result\n",
    "evr = [1-sum(pca.explained_variance_ratio_[:i+1]) for i in range(len(pca.explained_variance_ratio_))]\n",
    "plt.plot(range(1,n_components+1),evr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function and Gradient #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some useful functions. \n",
    "\n",
    "init_mask: Create a mask matrix that indicates where Y has meaningful values. \n",
    "\n",
    "loss: Sum-of-squares loss, with a regularization term to prevent overfitting. The matrices theta and X are multiplied to give a \"best guess\", which is then compared with the target matrix Y, but only in locations where a rating has been given.\n",
    "\n",
    "gradient: Derivative of loss with respect to theta and X, with a regularization term. \n",
    "\n",
    "These functions will be useful in performing gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 12\n",
    "filter_size = min(100,len(mat[0]))\n",
    "mat = mat[:,range(filter_size)] if len(mat[0])>filter_size else mat #for speed\n",
    "global mask,n_repos,n_langs,reg_param\n",
    "reg_param = 0.00001\n",
    "\n",
    "#mask (R matrix)\n",
    "def init_mask(Y=mat):\n",
    "    f = np.vectorize(lambda x: 1 if x>0 else 0)\n",
    "    return f(Y),len(Y),len(Y[0])\n",
    "\n",
    "#loss (sum of squares, with regularization)\n",
    "def loss(args, Y=mat):\n",
    "    theta = np.reshape(args[:n_repos*n_features],(n_repos,n_features))\n",
    "    X = np.reshape(args[n_repos*n_features:],(n_langs,n_features))\n",
    "    g = np.vectorize(lambda x: x*x)\n",
    "    return 0.5*np.sum(np.multiply(g(np.subtract(np.matmul(theta,np.transpose(X)),Y)),mask))+reg_param/2*np.sum(g(args))\n",
    "\n",
    "#gradient\n",
    "def gradient(args, Y=mat):\n",
    "    theta = np.reshape(args[:n_repos*n_features],(n_repos,n_features))\n",
    "    X = np.reshape(args[n_repos*n_features:],(n_langs,n_features))\n",
    "    X_grad = np.matmul(np.transpose(np.multiply(np.subtract(np.matmul(theta,np.transpose(X)),Y),mask)),theta)+reg_param*X\n",
    "    theta_grad = np.matmul(np.multiply(np.subtract(np.matmul(theta,np.transpose(X)),Y),mask),X)+reg_param*theta\n",
    "    return np.concatenate((np.reshape(theta_grad,-1),np.reshape(X_grad,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is performed using loss and gradient as defined above. This will iteratively improve matrices theta and X, so that their product more closely matches the target matrix Y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as op\n",
    "\n",
    "def train(Y=mat):\n",
    "    #reshape into 1D format preferred by fmin_cg\n",
    "    theta = np.random.rand(n_repos,n_features)\n",
    "    X = np.random.rand(n_langs,n_features)\n",
    "    args = np.concatenate((np.reshape(theta,-1),np.reshape(X,-1)))\n",
    "\n",
    "    #use fmin_cg to perform gradient descent\n",
    "    args = op.fmin_cg(loss,args,gradient)\n",
    "\n",
    "    #reshape into a usable format\n",
    "    theta = np.reshape(args[:n_repos*n_features],(n_repos,n_features))\n",
    "    X = np.reshape(args[n_repos*n_features:],(n_langs,n_features))\n",
    "    \n",
    "    return theta,X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can test the recommender system. Type in your favorite language (or a space-separated list of your favourite languages), and 5 new languages will be recommended for you to learn. The training process may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter some languages: r python\n",
      "Training...\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000479\n",
      "         Iterations: 20404\n",
      "         Function evaluations: 31633\n",
      "         Gradient evaluations: 31633\n",
      "\n",
      "1: PHP - 0.756688275989\n",
      "2: C - 0.393447324958\n",
      "3: F# - 0.28399667921\n",
      "4: Groff - 0.267626254453\n",
      "5: C# - 0.258137024312\n"
     ]
    }
   ],
   "source": [
    "#process input\n",
    "string = raw_input(\"Enter some languages: \")\n",
    "print('Training...')\n",
    "langs = string.split(' ')\n",
    "lc_names = {str(name).lower(): name_to_index[name] for name in name_to_index}\n",
    "\n",
    "#create extra row to append to Y matrix\n",
    "test = np.zeros((1,len(names)))\n",
    "known = set()\n",
    "for lang in langs:\n",
    "    if lang.lower() in lc_names:\n",
    "        test[0][lc_names[lang.lower()]] = 1\n",
    "        known.add(lc_names[lang.lower()])\n",
    "               \n",
    "#training\n",
    "mat = np.concatenate((mat,test[:,range(filter_size)]),0)\n",
    "mask,n_repos,n_langs = init_mask()\n",
    "theta,X = train(mat)\n",
    "mat = mat[:-1]\n",
    "    \n",
    "#find top predictions\n",
    "predictions = np.matmul(theta,np.transpose(X))[-1].tolist()\n",
    "predictions = sorted([(abs(j),i) for i,j in enumerate(predictions)],reverse=True)\n",
    "    \n",
    "#print predictions\n",
    "print('')\n",
    "i = 0\n",
    "for val,name in predictions:\n",
    "    if name not in known:\n",
    "        print(str(i+1)+': '+names[name]+' - '+str(val))\n",
    "        i+=1\n",
    "    if i>=5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you type in the list of languages, the recommender system adds that extra row to target matrix Y. Then, training is performed on your language preferences simultaneously as those of all the repositories in the sample. Finally, the trained matrices theta and X are multiplied, and the last row corresponds to the predicted ratings based on your preferences. The highest values are the languages recommended to you. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
