{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering #\n",
    "\n",
    "Collaborative filtering is a popular approach to creating recommender systems. Suppose we have the following problem:\n",
    "\n",
    "User A gave five stars to _Titanic_ and _The Notebook_, and one star to _Captain America_ and _Dark Knight Rises_. Should we recommend to User A a film like _Love Actually_? What about _Batman vs Superman_?\n",
    "\n",
    "In this case it's easy to tell what User A prefers since we have prior knowledge about the films. But how can we develop recommendations without this knowledge? \n",
    "\n",
    "It turns out that if we have rating data from many users it's possible to learn the underlying features that define a movie (genre, certain actors/directors, etc.) as well as the preferences of each user for each feature. Then, by identifying the features for a particular movie, and the preferences of a particular user, we can decide whether that movie would be a good recommendation. \n",
    "\n",
    "# Low Rank Matrix Factorization #\n",
    "\n",
    "One method of implementing collaborative filtering is low rank matrix factorization. Suppose we have a matrix of ratings, with one column for each user and one row for each item. Call this matrix $Y$. A small number of the elements in the matrix will have values (the rating user A gives to item B, if it exists), but the vast majority of elements will be unknown. We also have a matrix $R$ which contains 1 in locations where a rating exists and 0 where a rating has not been given. Both $R$ and $Y$ have dimension $n_{items}$ by $n_{users}$. \n",
    "\n",
    "The process described above of learning underlying features and preferences is described mathematically by:\n",
    "\n",
    "$ Y = X \\theta^{T} $\n",
    "\n",
    "$X$ is a matrix with dimension $n_{items}$ by $n_{features}$ and $\\theta$ is a matrix with dimension $n_{users}$ by $n_{features}$. Each row in $X$ is the representation of a particular item as a linear combination of features, and each row in $\\theta$ represents the preferences of a particular user for each feature. Note that a feature might be some characteristic such as genre or author - but it may also be very difficult to interpret. The beauty of the algorithm is that it will automatically choose the most meaningful features.\n",
    "\n",
    "# Training and Implementation #\n",
    "\n",
    "The goal of our algorithm is to find appropriate matrices $X$ and $\\theta$ such that $X \\theta^{T}$ approximates $Y$. However, it only needs to approximate $Y$'s values where a rating has actually been given - for some user A who has not rated item B, the value given by $X \\theta^{T}$ at column A and row B is the _predicted_ rating that user A will give to item B. \n",
    "\n",
    "We can find $X$ and $\\theta$ using gradient descent. The loss function will be the sum-of-squares loss between $X \\theta^{T}$ and $Y$, _but only evaluated on locations where a rating has been given_, i.e. where $R_{i,j}=1$. Similarly, the gradient is only computed at these locations as well. \n",
    "\n",
    "For this particular analysis, the goal is to recommend programming languages for you to learn, given some languages you already like. We will approximate the preferences of users with the languages used in GitHub repositories. The items we rate will be languages. Once we compute $X$ and $\\theta$, the recommended languages will be those with the highest predicted ratings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquiring Data From BigQuery #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import a relatively small number of repositories (for speed) and their language details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 1\n",
      "ASP: 102 bytes\n",
      "C#: 264446 bytes\n",
      "CSS: 1100 bytes\n",
      "HTML: 1764 bytes\n",
      "PowerShell: 22990 bytes\n",
      "\n",
      "Repository 2\n",
      "CSS: 24952 bytes\n",
      "HTML: 24503 bytes\n",
      "JavaScript: 50223 bytes\n",
      "Python: 454411 bytes\n",
      "\n",
      "Repository 3\n",
      "C: 45679 bytes\n",
      "Makefile: 513 bytes\n",
      "\n",
      "Repository 4\n",
      "CSS: 11923 bytes\n",
      "HTML: 225 bytes\n",
      "JavaScript: 89398 bytes\n",
      "Vue: 41906 bytes\n",
      "\n",
      "Repository 5\n",
      "CSS: 4083 bytes\n",
      "CoffeeScript: 6911 bytes\n",
      "HTML: 17133 bytes\n",
      "JavaScript: 10024 bytes\n",
      "\n",
      "Repository 6\n",
      "C: 20996 bytes\n",
      "CMake: 4907 bytes\n",
      "Shell: 60 bytes\n",
      "\n",
      "Repository 7\n",
      "CSS: 4848 bytes\n",
      "JavaScript: 1064 bytes\n",
      "Makefile: 1581 bytes\n",
      "PHP: 402237 bytes\n",
      "Shell: 11773 bytes\n",
      "\n",
      "Repository 8\n",
      "C++: 12988 bytes\n",
      "CMake: 310 bytes\n",
      "\n",
      "Repository 9\n",
      "C: 1937 bytes\n",
      "C++: 3251951 bytes\n",
      "CMake: 19487 bytes\n",
      "Makefile: 4555 bytes\n",
      "Python: 190686 bytes\n",
      "Shell: 343386 bytes\n",
      "\n",
      "Repository 10\n",
      "JavaScript: 1586 bytes\n",
      "Ruby: 19189 bytes\n",
      "Shell: 131 bytes\n",
      "\n",
      "...\n",
      "160 repositories\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "#random sample of 300 repositories\n",
    "QUERY = \"\"\"\n",
    "        SELECT repo_name, language\n",
    "        FROM `bigquery-public-data.github_repos.languages`\n",
    "        ORDER BY rand()\n",
    "        LIMIT 300\n",
    "        \"\"\"\n",
    "\n",
    "query_job = client.query(QUERY)\n",
    "\n",
    "#filter out repositories with only one language\n",
    "iterator = query_job.result(timeout=30)\n",
    "rows = list(iterator)\n",
    "rows = list(filter(lambda row: len(row.language)>1,rows))\n",
    "\n",
    "#print some repositories\n",
    "for i in range(10):\n",
    "    print('Repository '+str(i+1))\n",
    "    for j in rows[i].language:\n",
    "        print(j[u'name']+': '+str(j[u'bytes'])+' bytes')\n",
    "    print('')\n",
    "print('...')\n",
    "print(str(len(rows))+' repositories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Languages #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of all languages in the given sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeScript\n",
      "Java\n",
      "Scala\n",
      "ApacheConf\n",
      "JavaScript\n",
      "Makefile\n",
      "QMake\n",
      "Perl\n",
      "IDL\n",
      "R\n",
      "...\n",
      "40 languages\n"
     ]
    }
   ],
   "source": [
    "#create dictionary of language names to matrix columns\n",
    "names = {}\n",
    "for i in range(len(rows)):\n",
    "    for j in rows[i].language:\n",
    "        if j[u'name'] in names:\n",
    "            names[j[u'name']]+=1\n",
    "        else:\n",
    "            names[j[u'name']]=1\n",
    "\n",
    "#filter out languages that only occur once\n",
    "names = [n for n in names if names[n]>1]\n",
    "for i in range(10):\n",
    "    print(names[i])\n",
    "print('...')\n",
    "\n",
    "#print some languages\n",
    "name_to_index = {}\n",
    "for j,i in enumerate(names):\n",
    "    name_to_index[i] = j\n",
    "print(str(len(names))+\" languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repository-Language Matrix #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix where each row represents a repository and each column represents a language. This matrix is our Y (i.e. what we are trying to predict). Here, if a language A is used in repository B, this is considered as repository B giving A a rating. If A is not used in B, then there is no rating (rather than a rating of 0). \n",
    "\n",
    "The value in the matrix is the log of number of bytes in the repository in that particular language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "#create matrix\n",
    "global mat\n",
    "mat = np.zeros((len(rows),len(names)))\n",
    "for i,row in enumerate(rows):\n",
    "    #total = sum([log(lang[u'bytes']+1) for lang in row[1]])\n",
    "    for lang in row.language:\n",
    "        if lang[u'name'] in name_to_index:\n",
    "            mat[i][name_to_index[lang[u'name']]] = log(lang[u'bytes'])\n",
    "            #mat[i][name_to_index[lang[u'name']]] = log(lang[u'bytes']+1)/total\n",
    "mat = mat[~np.all(mat==0,axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PCA we can define roughly the number of features we want to identify the low rank matrix factorization. The graph below shows the amount of unexplained variance plotted against the number of components used. The \"elbow\" of the graph (at around n=12) is typically used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f708ece04d0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f708ef9df50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#compute PCA\n",
    "n_components = min(50,len(names))\n",
    "pca = PCA(n_components=n_components)\n",
    "transformed = pca.fit_transform(mat) \n",
    "\n",
    "#display result\n",
    "evr = [1-sum(pca.explained_variance_ratio_[:i+1]) for i in range(len(pca.explained_variance_ratio_))]\n",
    "plt.plot(range(1,n_components+1),evr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function and Gradient #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some useful functions. \n",
    "\n",
    "init_mask: Create a mask matrix that indicates where Y has meaningful values. \n",
    "\n",
    "loss: Sum-of-squares loss, with a regularization term to prevent overfitting. The matrices theta and X are multiplied to give a \"best guess\", which is then compared with the target matrix Y, but only in locations where a rating has been given.\n",
    "\n",
    "gradient: Derivative of loss with respect to theta and X, with a regularization term. \n",
    "\n",
    "These functions will be useful in performing gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_size = min(100,len(mat[0]))\n",
    "mat = mat[:,range(filter_size)] if len(mat[0])>filter_size else mat #for speed\n",
    "\n",
    "#mask (R matrix)\n",
    "def init_mask(Y):\n",
    "    f = np.vectorize(lambda x: 1 if x>0 else 0)\n",
    "    return f(Y),len(Y),len(Y[0])\n",
    "\n",
    "#loss (sum of squares, with regularization)\n",
    "def loss(args,Y,mask,n_repos,n_langs,n_features,reg_param):\n",
    "    theta = np.reshape(args[:n_repos*n_features],(n_repos,n_features))\n",
    "    X = np.reshape(args[n_repos*n_features:],(n_langs,n_features))\n",
    "    g = np.vectorize(lambda x: x*x)\n",
    "    return 0.5*np.sum(np.multiply(g(np.subtract(np.matmul(theta,np.transpose(X)),Y)),mask))+reg_param/2*np.sum(g(args))\n",
    "\n",
    "#gradient\n",
    "def gradient(args,Y,mask,n_repos,n_langs,n_features,reg_param):\n",
    "    theta = np.reshape(args[:n_repos*n_features],(n_repos,n_features))\n",
    "    X = np.reshape(args[n_repos*n_features:],(n_langs,n_features))\n",
    "    X_grad = np.matmul(np.transpose(np.multiply(np.subtract(np.matmul(theta,np.transpose(X)),Y),mask)),theta)+reg_param*X\n",
    "    theta_grad = np.matmul(np.multiply(np.subtract(np.matmul(theta,np.transpose(X)),Y),mask),X)+reg_param*theta\n",
    "    return np.concatenate((np.reshape(theta_grad,-1),np.reshape(X_grad,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is performed using loss and gradient as defined above. This will iteratively improve matrices theta and X, so that their product more closely matches the target matrix Y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as op\n",
    "\n",
    "def train(Y,mask,n_repos,n_langs,n_features=10,reg_param=0.0000001):\n",
    "    #reshape into 1D format preferred by fmin_cg\n",
    "    theta = np.random.rand(n_repos,n_features)\n",
    "    X = np.random.rand(n_langs,n_features)\n",
    "    args = np.concatenate((np.reshape(theta,-1),np.reshape(X,-1)))\n",
    "\n",
    "    #use fmin_cg to perform gradient descent\n",
    "    args = op.fmin_cg(lambda x: loss(x,Y,mask,n_repos,n_langs,n_features,reg_param),args,lambda x: gradient(x,Y,mask,n_repos,n_langs,n_features,reg_param))\n",
    "\n",
    "    #reshape into a usable format\n",
    "    theta = np.reshape(args[:n_repos*n_features],(n_repos,n_features))\n",
    "    X = np.reshape(args[n_repos*n_features:],(n_langs,n_features))\n",
    "    \n",
    "    return theta,X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a function for recommendations. Unfortunately Kaggle's front end doesn't allow for user input, so we will test some inputs manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(string,Y):\n",
    "    #process input\n",
    "    print('Training...')\n",
    "    langs = string.split(' ')\n",
    "    lc_names = {str(name).lower(): name_to_index[name] for name in name_to_index}\n",
    "\n",
    "    #create extra row to append to Y matrix\n",
    "    test = np.zeros((1,len(names)))\n",
    "    known = set()\n",
    "    for lang in langs:\n",
    "        if lang.lower() in lc_names:\n",
    "            test[0][lc_names[lang.lower()]] = 1\n",
    "            known.add(lc_names[lang.lower()])\n",
    "\n",
    "    #training\n",
    "    Y = np.concatenate((Y,test[:,range(filter_size)]),0)\n",
    "    mask,n_repos,n_langs = init_mask(Y)\n",
    "    theta,X = train(Y,mask,n_repos,n_langs)\n",
    "    Y = Y[:-1]\n",
    "    \n",
    "    #plot features\n",
    "    for i in range(np.shape(X)[1]):\n",
    "        col = sorted([(X[j,i],j) for j in range(n_langs)],reverse=True)\n",
    "        #print('')\n",
    "        #for k in range(10):\n",
    "            #print(names[col[k][1]])\n",
    "\n",
    "    #find top predictions\n",
    "    predictions = np.matmul(theta,np.transpose(X))[-1].tolist()\n",
    "    predictions = sorted([(abs(j),i) for i,j in enumerate(predictions)],reverse=True)\n",
    "\n",
    "    #print predictions\n",
    "    print('')\n",
    "    i = 0\n",
    "    for val,name in predictions:\n",
    "        if name not in known:\n",
    "            print(str(i+1)+': '+names[name]+' - '+str(val))\n",
    "            i+=1\n",
    "        if i>=5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommender system adds the extra input row to target matrix Y. Then, training is performed on your language preferences simultaneously as those of all the repositories in the sample. Finally, the trained matrices theta and X are multiplied, and the last row corresponds to the predicted ratings based on your preferences. The highest values are the languages recommended to you. \n",
    "\n",
    "# Some Examples #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000093\n",
      "         Iterations: 156\n",
      "         Function evaluations: 240\n",
      "         Gradient evaluations: 240\n",
      "\n",
      "1: Arduino - 2.28937260554\n",
      "2: C# - 2.1988148073\n",
      "3: PHP - 2.15274078836\n",
      "4: C++ - 2.11193126621\n",
      "5: CSS - 2.089976025\n"
     ]
    }
   ],
   "source": [
    "recommend('python r',mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000095\n",
      "         Iterations: 251\n",
      "         Function evaluations: 384\n",
      "         Gradient evaluations: 384\n",
      "\n",
      "1: JavaScript - 3.28091731253\n",
      "2: Makefile - 3.23717325443\n",
      "3: TypeScript - 3.22846331194\n",
      "4: Arduino - 2.91141699067\n",
      "5: C++ - 2.83684639984\n"
     ]
    }
   ],
   "source": [
    "recommend('html css',mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000095\n",
      "         Iterations: 186\n",
      "         Function evaluations: 287\n",
      "         Gradient evaluations: 287\n",
      "\n",
      "1: Python - 4.09376715574\n",
      "2: C++ - 4.00002558111\n",
      "3: TypeScript - 3.9731653244\n",
      "4: C# - 3.5329519996\n",
      "5: JavaScript - 3.13825608832\n"
     ]
    }
   ],
   "source": [
    "recommend('c',mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000094\n",
      "         Iterations: 233\n",
      "         Function evaluations: 358\n",
      "         Gradient evaluations: 358\n",
      "\n",
      "1: C - 3.54456153483\n",
      "2: Makefile - 2.74514165747\n",
      "3: HTML - 2.65422492064\n",
      "4: PHP - 2.61971682198\n",
      "5: Go - 2.56340367282\n"
     ]
    }
   ],
   "source": [
    "recommend('java',mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000094\n",
      "         Iterations: 225\n",
      "         Function evaluations: 337\n",
      "         Gradient evaluations: 337\n",
      "\n",
      "1: Shell - 4.52769699282\n",
      "2: C# - 4.2828142518\n",
      "3: JavaScript - 4.01432142617\n",
      "4: Java - 3.95019740991\n",
      "5: C++ - 3.92307197203\n"
     ]
    }
   ],
   "source": [
    "recommend('ruby',mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to fork this notebook and try out some more examples, or adjust the parameters (regularization especially seems to make a big difference)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
